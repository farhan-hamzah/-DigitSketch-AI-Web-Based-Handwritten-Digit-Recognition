{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "805efbb5-6881-4fed-922e-debf9b7fbcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8540 - loss: 0.4493 - val_accuracy: 0.9858 - val_loss: 0.0492\n",
      "Epoch 2/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9782 - loss: 0.0763 - val_accuracy: 0.9887 - val_loss: 0.0413\n",
      "Epoch 3/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9829 - loss: 0.0579 - val_accuracy: 0.9900 - val_loss: 0.0369\n",
      "Epoch 4/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0457 - val_accuracy: 0.9907 - val_loss: 0.0351\n",
      "Epoch 5/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9892 - loss: 0.0349 - val_accuracy: 0.9908 - val_loss: 0.0364\n",
      "Epoch 6/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9910 - loss: 0.0298 - val_accuracy: 0.9917 - val_loss: 0.0348\n",
      "Epoch 7/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.0250 - val_accuracy: 0.9917 - val_loss: 0.0317\n",
      "Epoch 8/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0224 - val_accuracy: 0.9902 - val_loss: 0.0430\n",
      "Epoch 9/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.0217 - val_accuracy: 0.9910 - val_loss: 0.0367\n",
      "Epoch 10/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0179 - val_accuracy: 0.9912 - val_loss: 0.0388\n",
      "Test accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "early_stop = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "model.save(\"mnist_cnn_improved.keras\")\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    try:\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)        \n",
    "        if img is None:\n",
    "            img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
    "            img = image.img_to_array(img)\n",
    "            img = img.reshape(28, 28)\n",
    "        else:\n",
    "            img = cv2.resize(img, (28, 28))\n",
    "        img = img / 255.0\n",
    "        if np.mean(img) > 0.5:  \n",
    "            img = 1 - img\n",
    "        img = np.where(img > 0.3, 1.0, 0.0)\n",
    "        img = img.reshape(1, 28, 28, 1)        \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error dalam preprocessing: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def predict_digit(img_path, model):\n",
    "    try:\n",
    "        img_array = preprocess_image(img_path)\n",
    "        if img_array is None:\n",
    "            print(\"Gagal memproses gambar\")\n",
    "            return None, 0\n",
    "        prediction = model.predict(img_array, verbose=0)\n",
    "        predicted_digit = np.argmax(prediction)\n",
    "        confidence = np.max(prediction) * 100\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        try:\n",
    "            original_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if original_img is not None:\n",
    "                plt.imshow(original_img, cmap='gray')\n",
    "            else:\n",
    "                original_img = image.load_img(img_path, color_mode='grayscale')\n",
    "                plt.imshow(original_img, cmap='gray')\n",
    "        except:\n",
    "            print(\"Tidak bisa menampilkan gambar asli\")\n",
    "        \n",
    "        plt.title('Gambar Asli')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(img_array.reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'Setelah Preprocessing')\n",
    "        plt.axis('off')        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        digits = range(10)\n",
    "        probabilities = prediction[0] * 100\n",
    "        bars = plt.bar(digits, probabilities)\n",
    "        bars[predicted_digit].set_color('red')\n",
    "        plt.title(f'Prediksi: {predicted_digit} ({confidence:.1f}%)')\n",
    "        plt.xlabel('Digit')\n",
    "        plt.ylabel('Probabilitas (%)')\n",
    "        plt.xticks(digits)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Probabilitas per kelas:\")\n",
    "        for i, prob in enumerate(prediction[0]):\n",
    "            print(f\"Digit {i}: {prob:.4f} ({prob*100:.1f}%)\")\n",
    "        \n",
    "        if confidence < 70:\n",
    "            print(f\"\\n⚠️  Peringatan: Confidence rendah ({confidence:.1f}%)\")\n",
    "            print(\"Kemungkinan penyebab:\")\n",
    "            print(\"- Gambar tidak jelas/blur\")\n",
    "            print(\"- Angka tidak terpusat\")\n",
    "            print(\"- Kontras rendah\")\n",
    "            print(\"- Gaya penulisan sangat berbeda dari dataset MNIST\")\n",
    "        \n",
    "        return predicted_digit, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error dalam prediksi: {str(e)}\")\n",
    "        return None, 0\n",
    "\n",
    "def test_prediction(img_path):\n",
    "    try:\n",
    "        model = keras.models.load_model(\"mnist_cnn_improved.keras\")\n",
    "        print(\"Model berhasil dimuat!\")\n",
    "        predicted_digit, confidence = predict_digit(img_path, model)\n",
    "        if predicted_digit is not None:\n",
    "            print(f\"\\n📊 Hasil Prediksi: {predicted_digit}\")\n",
    "            print(f\"🎯 Confidence: {confidence:.1f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"Pastikan model sudah dilatih dan file gambar tersedia\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2555d76d-16d8-4a99-93b4-033d091aab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediksi_angka(model, img_path):\n",
    "    img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # (1, 28, 28, 1)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_digit = np.argmax(prediction)\n",
    "    plt.imshow(img_array.reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Prediksi angka: {predicted_digit}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dc8d567-357b-4484-ac0a-648d46cd9e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model memprediksi angka: 3\n"
     ]
    }
   ],
   "source": [
    "hasil = prediksi_angka(model, \"testAngka3.png\")\n",
    "print(\"Model memprediksi angka:\", hasil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65186422-27d0-496a-9cd2-76cab317ddee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
