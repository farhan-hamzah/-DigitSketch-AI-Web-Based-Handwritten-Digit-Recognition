{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "805efbb5-6881-4fed-922e-debf9b7fbcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8607 - loss: 0.4312 - val_accuracy: 0.9873 - val_loss: 0.0392\n",
      "Epoch 2/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9774 - loss: 0.0734 - val_accuracy: 0.9898 - val_loss: 0.0362\n",
      "Epoch 3/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9833 - loss: 0.0555 - val_accuracy: 0.9898 - val_loss: 0.0339\n",
      "Epoch 4/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9872 - loss: 0.0403 - val_accuracy: 0.9908 - val_loss: 0.0331\n",
      "Epoch 5/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.0337 - val_accuracy: 0.9922 - val_loss: 0.0293\n",
      "Epoch 6/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0288 - val_accuracy: 0.9925 - val_loss: 0.0293\n",
      "Epoch 7/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0258 - val_accuracy: 0.9922 - val_loss: 0.0333\n",
      "Epoch 8/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0237 - val_accuracy: 0.9915 - val_loss: 0.0345\n",
      "Test accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "early_stop = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "model.save(\"mnist_cnn_improved.keras\")\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    try:\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)        \n",
    "        if img is None:\n",
    "            img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
    "            img = image.img_to_array(img)\n",
    "            img = img.reshape(28, 28)\n",
    "        else:\n",
    "            img = cv2.resize(img, (28, 28))\n",
    "        img = img / 255.0\n",
    "        if np.mean(img) > 0.5:  \n",
    "            img = 1 - img\n",
    "        img = np.where(img > 0.3, 1.0, 0.0)\n",
    "        img = img.reshape(1, 28, 28, 1)        \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error dalam preprocessing: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def predict_digit(img_path, model):\n",
    "    try:\n",
    "        img_array = preprocess_image(img_path)\n",
    "        if img_array is None:\n",
    "            print(\"Gagal memproses gambar\")\n",
    "            return None, 0\n",
    "        prediction = model.predict(img_array, verbose=0)\n",
    "        predicted_digit = np.argmax(prediction)\n",
    "        confidence = np.max(prediction) * 100\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        try:\n",
    "            original_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if original_img is not None:\n",
    "                plt.imshow(original_img, cmap='gray')\n",
    "            else:\n",
    "                original_img = image.load_img(img_path, color_mode='grayscale')\n",
    "                plt.imshow(original_img, cmap='gray')\n",
    "        except:\n",
    "            print(\"Tidak bisa menampilkan gambar asli\")\n",
    "        \n",
    "        plt.title('Gambar Asli')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(img_array.reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'Setelah Preprocessing')\n",
    "        plt.axis('off')        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        digits = range(10)\n",
    "        probabilities = prediction[0] * 100\n",
    "        bars = plt.bar(digits, probabilities)\n",
    "        bars[predicted_digit].set_color('red')\n",
    "        plt.title(f'Prediksi: {predicted_digit} ({confidence:.1f}%)')\n",
    "        plt.xlabel('Digit')\n",
    "        plt.ylabel('Probabilitas (%)')\n",
    "        plt.xticks(digits)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Probabilitas per kelas:\")\n",
    "        for i, prob in enumerate(prediction[0]):\n",
    "            print(f\"Digit {i}: {prob:.4f} ({prob*100:.1f}%)\")\n",
    "        \n",
    "        if confidence < 70:\n",
    "            print(f\"\\nâš ï¸  Peringatan: Confidence rendah ({confidence:.1f}%)\")\n",
    "            print(\"Kemungkinan penyebab:\")\n",
    "            print(\"- Gambar tidak jelas/blur\")\n",
    "            print(\"- Angka tidak terpusat\")\n",
    "            print(\"- Kontras rendah\")\n",
    "            print(\"- Gaya penulisan sangat berbeda dari dataset MNIST\")\n",
    "        \n",
    "        return predicted_digit, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error dalam prediksi: {str(e)}\")\n",
    "        return None, 0\n",
    "\n",
    "def test_prediction(img_path):\n",
    "    try:\n",
    "        model = keras.models.load_model(\"mnist_cnn_improved.keras\")\n",
    "        print(\"Model berhasil dimuat!\")\n",
    "        predicted_digit, confidence = predict_digit(img_path, model)\n",
    "        if predicted_digit is not None:\n",
    "            print(f\"\\nðŸ“Š Hasil Prediksi: {predicted_digit}\")\n",
    "            print(f\"ðŸŽ¯ Confidence: {confidence:.1f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"Pastikan model sudah dilatih dan file gambar tersedia\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2555d76d-16d8-4a99-93b4-033d091aab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediksi_angka(model, img_path):\n",
    "    img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # (1, 28, 28, 1)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_digit = np.argmax(prediction)\n",
    "    plt.imshow(img_array.reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Prediksi angka: {predicted_digit}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc8d567-357b-4484-ac0a-648d46cd9e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model memprediksi angka: 9\n"
     ]
    }
   ],
   "source": [
    "hasil = prediksi_angka(model, \"testAngka9.png\")\n",
    "print(\"Model memprediksi angka:\", hasil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65186422-27d0-496a-9cd2-76cab317ddee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
